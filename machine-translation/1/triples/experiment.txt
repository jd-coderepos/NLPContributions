(Contribution||has||Experiment)
(Experiment||called||Character-Level Machine Translation)
(Character-Level Machine Translation||has||Hyperparameters)
(Hyperparameters||size of the masked kernel||target network is 3)
(Hyperparameters||optimization||Adam)
(Adam||learning rate||0.0003)
(Hyperparameters||size of the kernel||source network is 3)
(Hyperparameters||has||30 residual blocks)
(30 residual blocks||in||encoder)
(30 residual blocks||in||decoder)
(Hyperparameters||residual blocks||arranged in sets of five)
(arranged in sets of five||with||dilation rates)
(dilation rates||of||1, 2, 4, 8 and 16)
(Hyperparameters||hidden units||d is 800)
(Character-Level Machine Translation||has||Results)
(Results||on||NewsTest 2015)
(NewsTest 2015||achieves||best published results to date)
(Results||on||NewsTest 2014)
(NewsTest 2014||achieves||highest performance)
(highest performance||in||character-level and subword-level neural machine translation)
(NewsTest 2014||is||second)
(second||to||version of GNMT that uses word-pieces)
(second||compared to||word-level systems)
(Experiment||called||Character Prediction)
(Character Prediction||has||Hyperparameters)
(Hyperparameters||masked kernel||size 3)
(Hyperparameters||number of hidden units||d is 512)
(Hyperparameters||optimization||Adam)
(Adam||learning rate||0.0003)
(Adam||weight decay||0.0001)
(Hyperparameters||dropout||probability of 0.1)
(Hyperparameters||residual blocks||30)
(30||split into||six sets of five blocks)
(six sets of five blocks||for||five blocks in each set)
(five blocks in each set||dilation rates||1; 2; 4; 8 and 16)
(Hyperparameters||sample||batch of sequences)
(batch of sequences||of||500 characters each)
(500 characters each||use||first 100 characters as the minimum context)
(500 characters each||predict||latter 400 characters)
(Character Prediction||has||Results)
(Results||achieves||1.31 bits/character on the test set)
