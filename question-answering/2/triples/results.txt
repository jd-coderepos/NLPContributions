(Contribution||has||Results)
(Results||test||ability to rerank answers)
(ability to rerank answers||on||companion QA set)
(companion QA set||added||all Reverb facts)
(all Reverb facts||to||memory)
(memory||without||any retraining)
(companion QA set||best results||accuracy)
(accuracy||are||67%)
(accuracy||are||68%)
(68%||for||ensemble of 5 models)
(Results||on||main benchmark WebQuestions)
(main benchmark WebQuestions||achieve||excellent results)
(excellent results||F1-scores||41.9% and 42.2%)
(Results||on||three datasets)
(three datasets||improves performance||training on both datasets only)
(three datasets||perform poorly||models trained on a single QA dataset perform poorly on the other datasets)
(Results||on||new SimpleQuestions dataset)
(new SimpleQuestions dataset||accuracy||62 - 63%)
