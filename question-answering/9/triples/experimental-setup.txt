(Contribution||has||Experimental setup)
(Experimental setup||couple||input and forget gates)
(input and forget gates||in||LSTMs)
(Experimental setup||use||single dropout mask)
(single dropout mask||apply dropout||across all LSTM time-steps)
(Experimental setup||Hidden layers||feed forward neural networks)
(feed forward neural networks||use||rectified linear units)
(Experimental setup||implemented using||TensorFlow)
(Experimental setup||represent each of the words||question and document)
(question and document||using||300 dimensional GloVe embeddings)
(300 dimensional GloVe embeddings||trained on||corpus of 840bn words)
(Experimental setup||best model||50d LSTM states)
(Experimental setup||best model||two-layer BiLSTMs)
(two-layer BiLSTMs||for||span encoder and the passage-independent question representation)
(Experimental setup||best model||dropout)
(dropout||of||0.1)
(Experimental setup||best model||learning rate decay)
(learning rate decay||of||5%)
(5%||every||10k steps)
(Experimental setup||trained on||SQUAD training set)
(SQUAD training set||using||ADAM (Kingma & Ba, 2015) optimizer)
(ADAM (Kingma & Ba, 2015) optimizer||with||mini-batch size)
(mini-batch size||of||4)
(Experimental setup||trained using||10 asynchronous training threads)
(10 asynchronous training threads||on||single machine)
(Experimental setup||ran||grid searches)
(grid searches||number of stacked LSTM layers||(1,2,3))
(grid searches||width and depth||feed forward neural networks)
(grid searches||dimensionality||LSTM hidden states)
(grid searches||dropout||LSTMs)
(grid searches||decay multiplier||[0.9, 0.95, 1.0])
