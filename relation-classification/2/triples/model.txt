(Contribution||has||Model)
(Model||is||multi-head joint model)
(Model||from sentence||The basic layers of the model, shown in Fig. 1, are: (i) embedding layer, (ii) bidirectional sequential LSTM (BiLSTM) layer, (iii) CRF layer and the (iv) sigmoid scoring layer.)
(Model||basic layers||embedding layer)
(Model||basic layers||bidirectional sequential LSTM (BiLSTM) layer)
(Model||basic layers||CRF layer)
(Model||basic layers||sigmoid scoring layer)
(Model||input||word vectors (i.e., word embeddings))
(Model||from sentence||The input of our model is a sequence of tokens (i.e., words of the sentence) which are then represented as word vectors (i.e., word embeddings).)
(Model||outputs||entity recognition label)
(Model||outputs||set of tuples comprising the head tokens of the entity and the types of relations between them)
(Model||from sentence||The outputs for each token (e.g., Smith) are twofold: (i) an entity recognition label (e.g., I-PER, denoting the token is inside a named entity of type PER) and (ii) a set of tuples comprising the head tokens of the entity and the types of relations between them (e.g., {(Center, Works for), (Atlanta, Lives in)}).)
