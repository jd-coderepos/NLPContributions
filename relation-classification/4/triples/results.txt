(Contribution||has||Results)
(Results||effect||Path-centric Pruning)
(Path-centric Pruning||compare||two GCN models and the Tree-LSTM)
(two GCN models and the Tree-LSTM||when||pruning distance K is varied)
(Path-centric Pruning||when K = 1||performance of all three models peaks)
(performance of all three models peaks||confirms our hypothesis||incorporating off-path information is crucial to relation extraction)
(performance of all three models peaks||outperforming||dependency path-based counterpart (K = 0))
(Path-centric Pruning||find||all three models are less effective)
(all three models are less effective||when||entire dependency tree is present)
(entire dependency tree is present||indicating||including extra information hurts performance)
(Path-centric Pruning||contextualizing||GCN)
(GCN||makes it||less sensitive to changes in the tree structures provided)
(Results||on||TACRED Dataset)
(TACRED Dataset||from sentence||We observe that our GCN model outperforms all dependency-based models by at least 1.6 F1.)
(TACRED Dataset||observe||GCN model outperforms all dependency-based models)
(GCN model outperforms all dependency-based models||by||at least 1.6 F1)
(TACRED Dataset||further outperforms||C-GCN model further outperforms the strong PA-LSTM model)
(C-GCN model further outperforms the strong PA-LSTM model||using||contextualized word representations)
(C-GCN model further outperforms the strong PA-LSTM model||by||1.3 F1)
(TACRED Dataset||from sentence||In addition, we find our model improves upon other dependency-based models in both precision and recall.)
(TACRED Dataset||improves upon other dependency-based models||our model improves upon other dependency-based models in both precision and recall)
(TACRED Dataset||from sentence||Comparing the C-GCN model with the GCN model, we find that the gain mainly comes from improved recall.)
(TACRED Dataset||comparing C-GCN model with the GCN model||gain mainly comes from improved recall)
(TACRED Dataset||from sentence||As we will show in Section 6.2, we find that our GCN models have complementary strengths when compared to the PA-LSTM.)
(TACRED Dataset||compared to the PA-LSTM||our GCN models have complementary strengths)
(Results||on||SemEval Dataset)
(SemEval Dataset||with-entity evaluation||C-GCN model outperforms all existing dependency-based neural models)
(SemEval Dataset||from sentence||We find that under the conventional with-entity evaluation, our C-GCN model outperforms all existing dependency-based neural models on this separate dataset.)
(SemEval Dataset||incorporating off-path information||our model outperforms the previous shortest dependency path-based model (SDP-LSTM))
(SemEval Dataset||from sentence||Notably, by properly incorporating off-path information, our model outperforms the previous shortest dependency path-based model (SDP-LSTM).)
(SemEval Dataset||mask-entity evaluation||C-GCN model also outperforms PA-LSTM)
(C-GCN model also outperforms PA-LSTM||by||substantial margin)
