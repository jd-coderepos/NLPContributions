(Contribution||has||Model)
(Model||from sentence||In this paper, we present a novel end-to-end neural model for joint entity and relation extraction.)
(Model||is a||novel end-to-end neural model for joint entity and relation extraction)
(Model||mixture of||named entity recognition (NER) component)
(named entity recognition (NER) component||employs||BiLSTM-CRF architecture)
(BiLSTM-CRF architecture||to||predict entities from input word tokens)
(Model||mixture of||relation classification (RC) component)
(relation classification (RC) component||takes into account||second-order interactions over the latent features via a tensor)
(relation classification (RC) component||uses||another BiLSTM)
(another BiLSTM||to||learn latent features relevant for relation classification)
(learn latent features relevant for relation classification||based on||input words and the predicted NER labels)
(relation classification (RC) component||propose||novel use of the deep biaffine attention mechanism)
(Model||from sentence||As illustrated in Figure 1, our model architecture can be viewed as a mixture of a named entity recognition (NER) component and a relation classification (RC) component. Our NER component employs a BiLSTM-CRF architecture [10] to predict entities from input word tokens. Based on both the input words and the predicted NER labels, the RC component uses another BiLSTM to learn latent features relevant for relation classification. In contrast, our RC component takes into account second-order interactions over the latent features via a tensor. In particular, for relation classification we propose a novel use of the deep biaffine attention mechanism [7] which was first introduced in dependency parsing.)
