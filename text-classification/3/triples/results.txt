(Contribution||has||Results)
(Results||from||Experiment 1: Preprocessing effect)
(Experiment 1: Preprocessing effect||does not help||more complex pre-processing techniques)
(more complex pre-processing techniques||such as||lemmatization and multiword grouping)
(Experiment 1: Preprocessing effect||observe||a certain variability of results)
(a certain variability of results||depending on||preprocessing techniques)
(a certain variability of results||average variability||+-2.4%)
(+-2.4%||for||CNN+LSTM model)
(Results||from||Experiment 2: Cross-preprocessing)
(Experiment 2: Cross-preprocessing||do not seem to help||different preprocessing techniques)
(different preprocessing techniques||such as||lowercasing and lemmatizing)
(Experiment 2: Cross-preprocessing||consistently better results||multiword-wise embeddings)
(multiword-wise embeddings||on||vanilla setting)
(vanilla setting||in||eight of the nine datasets)
(Experiment 2: Cross-preprocessing||competitive||embeddings trained on a simple tokenized corpus)
(Experiment 2: Cross-preprocessing||exhibiting a better performance||multiword enhanced vectors)
(multiword enhanced vectors||on||single CNN model (best overall performance in seven of the nine datasets))
(multiword enhanced vectors||on||CNN+LSTM model (best performance in four datasets and in the same ballpark as the best results in four of the remaining five datasets))
