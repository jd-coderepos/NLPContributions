(Contribution||has||Hyperparameters)
(Hyperparameters||Adam||beta1 = 0.7)
(Hyperparameters||Adam||beta2 = 0.99)
(Hyperparameters||apply||weight dropout)
(weight dropout||0.5||to the RNN hidden-to-hidden matrix)
(Hyperparameters||apply||dropout)
(dropout||0.3||to RNN layers)
(dropout||0.05||to embedding layers)
(dropout||0.4||to layers)
(dropout||0.4||to input embedding layers)
(Hyperparameters||use||AWD-LSTM language model (Merity et al., 2017a))
(AWD-LSTM language model (Merity et al., 2017a)||hidden activations per layer||1150)
(AWD-LSTM language model (Merity et al., 2017a)||BPTT batch size||70)
(AWD-LSTM language model (Merity et al., 2017a)||layers||3)
(AWD-LSTM language model (Merity et al., 2017a)||embedding size||400)
(Hyperparameters||classifier||hidden layer)
(hidden layer||size||50)
(Hyperparameters||base learning rate||0.004 and 0.01)
(0.004 and 0.01||for||finetuning the LM and the classifier)
(Hyperparameters||batch size||64)
