(Contribution||has||Hyperparameters)
(Hyperparameters||GloVe word embeddings||K = 300)
(Hyperparameters||initialized||Out-Of-Vocabulary (OOV) words)
(Out-Of-Vocabulary (OOV) words||from||uniform distribution)
(uniform distribution||with||range [-0.01, 0.01])
(Hyperparameters||Adam (Kingma and Ba, 2014)||optimize all models)
(optimize all models||with||learning rate)
(learning rate||selected from||[1 x 10-3, 3 x 10-4, 2 x 10-4, 1 x 10-5])
(Hyperparameters||selected||batch size)
(batch size||from||[2, 8, 32, 128, 512])
(Hyperparameters||employed||Dropout regularization (Srivastava et al., 2014))
(Dropout regularization (Srivastava et al., 2014)||with||dropout rate)
(dropout rate||selected from||[0.2, 0.5, 0.7])
(Dropout regularization (Srivastava et al., 2014)||on||word embedding layer)
(Dropout regularization (Srivastava et al., 2014)||on||final MLP layer)
(Hyperparameters||employed||GloVe embeddings)
(GloVe embeddings||in||two ways to learn refined word embeddings)
(two ways to learn refined word embeddings||updating||each word embedding)
(each word embedding||during||training)
(two ways to learn refined word embeddings||training||300-dimensional Multilayer Perceptron (MLP) layer)
(300-dimensional Multilayer Perceptron (MLP) layer||with||ReLU activation)
(300-dimensional Multilayer Perceptron (MLP) layer||with||GloVe embeddings)
(GloVe embeddings||output||refined word embeddings)
(GloVe embeddings||as input to||MLP)
